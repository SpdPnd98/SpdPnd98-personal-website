





<!--  -->




<!--  -->

<!doctype html>
<html class="height-full">
  <head>
    <meta charset="utf-8">
    <meta name="description" content="PrefaceI am a student studying in Singapore Polytechnic, currently in year 3. I truly enjoy what my course, Diploma in Computer Engineering has to offer. However, I have yet to see a chance to explore some of my ideas I have since I was year one. Over the years of hackathons, projects, and most i..." />
    <title>Bryan Tee Pak Hong</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="/assets/styles.css" rel="stylesheet" type="text/css">
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="/favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
    <link rel="manifest" href="/favicon/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/favicone/ms-icon-144x144.png">
    <link rel="alternate" type="aplication/atom+xml" title="modelconverge's blogs" href="/feed.xml"/>
  </head>
  <body class="bg-pic container-no-scroll" >





  <div class="container-lg py-6 p-responsive text-center bg-contrast-blue height-full">

    

<div class="container-md p-3 p-sm-5 " style="text-align: center;">
  <table class="border border-0">
    <tbody class="border border-0">
    <tr class="border border-0">
      <td class="border border-0">
        <div style="text-align: center;">
          <div style="margin: auto; position: relative;">
            <img src="https://avatars2.githubusercontent.com/u/34470507?v=4" class="circle mt-3 mb-3" style="max-width: 150px; margin-left: auto; margin-right: auto;"> 
          </div>
        </div>
      </td>
      <td class="border border-0">
        <h1 class=" mb-2 lh-condensed text-left">Bryan <br/>Tee Pak Hong</h1>
         <p class="mb-3 f4 text-gray text-left">
          Get Up, Dress Up, Show Up, and Never Give Up!
        </p>
        <p class="btn btn-rss" style="text-align: left; float: left;">
          <a href="/feed.xml" target="_blank" >
            <img style="max-width: 20px; float: left;" src="/images/RSS_icon.jpeg"/>&nbspSubscribe
          </a>
        </p>
        
      </td>
    </tr>
    </tbody>
  </table>
</div>

<nav class="UnderlineNavi container-md"> 
    <div class="UnderlineNav-body" style="display: block">
      <a href="/" role="tab" title="Home" class="UnderlineNav-item selected">Blog</a>
      <a href="/digitalfabrication" role="tab" title="Digital Fabrication" class="UnderlineNav-item ">Digital Fabrication</a>
      <a href="/myprojects" role="tab" title="My Projects" class="UnderlineNav-item ">My Projects</a>
      <a href="/about" role="tab" title="About" class="UnderlineNav-item ">About</a>
    </div>
  </nav>

    <div class="container-xl f4 text-left border rounded-2 bg-white p-3 p-sm-5 mt-6">
      <p class="f5"><a href="/" class="d-flex flex-items-center"><svg height="16" class="octicon octicon-chevron-left mr-2 v-align-middle" fill="#0366d6" aria-label="Home" viewBox="0 0 16 16" version="1.1" width="16" role="img"><path fill-rule="evenodd" d="M9.78 12.78a.75.75 0 01-1.06 0L4.47 8.53a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 1.06L6.06 8l3.72 3.72a.75.75 0 010 1.06z"></path></svg>Back</a></p>
      <h1 class="f00-light lh-condensed">What is Reinforcement Learning (RL)</h1>
      <p class="text-gray ">Published Apr 23, 2019</p>
      
  
  <div class="article">
    <h1 id="preface">Preface</h1>
<p>I am a student studying in Singapore Polytechnic, currently in year 3. I truly enjoy what my course, Diploma in Computer Engineering has to offer. However, I have yet to see a chance to explore some of my ideas I have since I was year one. Over the years of hackathons, projects, and most importantly guidance from mentors and peers, I feel like I know enough to learn RL at my own pace. This blog is to document what I have learnt over a two-week from my school holiday.</p>

<h2 id="fundementals">FUNdementals</h2>
<p>To discuss RL in specific terms, it is important to understand the following terminology:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">agent</code> : this is an algorithm in your machine that you train to achieve your goal</li>
  <li><code class="language-plaintext highlighter-rouge">environment</code> : this is the place your <code class="language-plaintext highlighter-rouge">agent</code> interacts with</li>
  <li><code class="language-plaintext highlighter-rouge">state</code> :  The instantaneous situation the agent finds itself in in relation to other factors.</li>
  <li><code class="language-plaintext highlighter-rouge">action</code> : This is the step that your agent takes upon determining from the multitude of possible steps from a <code class="language-plaintext highlighter-rouge">state</code></li>
  <li><code class="language-plaintext highlighter-rouge">reward</code> : A feedback used to measure the success/failure of the <code class="language-plaintext highlighter-rouge">agent</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">discount</code> : As time goes on, we all die. This is why we include the discount factor, to maximize time to live and do not let the “end game” <code class="language-plaintext highlighter-rouge">action</code>s affect the early game performance.</li>
  <li><code class="language-plaintext highlighter-rouge">episode</code> : The session the agent runs from start to finish.</li>
</ul>

<p>At the core of RL, we want the agent to learn the best actions to achieve a particular outcome through trial and error. There are multiple methods to be discussed but releasing it all in one article just spoils all the fun hehehe. Today we focus more on the technical terms.</p>

<p>Using the definitions above, we can see how they come together. The <code class="language-plaintext highlighter-rouge">agent</code> is what we have designed. The <code class="language-plaintext highlighter-rouge">environment</code> is a function/black box that transforms the <code class="language-plaintext highlighter-rouge">agent</code>’s current <code class="language-plaintext highlighter-rouge">state</code> and <code class="language-plaintext highlighter-rouge">action</code> taken into the next <code class="language-plaintext highlighter-rouge">state</code> and a feedback(<code class="language-plaintext highlighter-rouge">reward</code>), while the <code class="language-plaintext highlighter-rouge">agent</code> <code class="language-plaintext highlighter-rouge">transforms</code> the new <code class="language-plaintext highlighter-rouge">state</code> and <code class="language-plaintext highlighter-rouge">reward</code> into a next <code class="language-plaintext highlighter-rouge">action</code>. The <code class="language-plaintext highlighter-rouge">agent</code>’s job is to approximate the <code class="language-plaintext highlighter-rouge">environment</code>’s function to find the maximum <code class="language-plaintext highlighter-rouge">reward</code> it produces after each <code class="language-plaintext highlighter-rouge">episode</code>. A <code class="language-plaintext highlighter-rouge">discount</code> can be added to allow high performance early in the <code class="language-plaintext highlighter-rouge">episode</code> (and possibly forever!).</p>

<p><img src="/images/RL-flow.png" alt="RL-flow" /></p>

<p>So, using the above phenomena, we can observe more phenomenas and they can be expressed mathematically. Hence, let’s also define a few terms:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">policy</code> : A strategy that the <code class="language-plaintext highlighter-rouge">agent</code> uses to determine the next <code class="language-plaintext highlighter-rouge">action</code> based on the current <code class="language-plaintext highlighter-rouge">state</code>. It maps <code class="language-plaintext highlighter-rouge">state</code>s to <code class="language-plaintext highlighter-rouge">action</code>s of highest <code class="language-plaintext highlighter-rouge">reward</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">Q-value</code> or <code class="language-plaintext highlighter-rouge">action-value</code> : <code class="language-plaintext highlighter-rouge">Q</code> is a abbreviation for <code class="language-plaintext highlighter-rouge">Quality</code>. This is the expected long-term return with <code class="language-plaintext highlighter-rouge">discount</code>, taking into consideration of <code class="language-plaintext highlighter-rouge">action</code>. This value maps <code class="language-plaintext highlighter-rouge">state-action pairs</code> to <code class="language-plaintext highlighter-rouge">rewards</code>, having a subtle difference with <code class="language-plaintext highlighter-rouge">policy</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">Value</code> : the overall expected <code class="language-plaintext highlighter-rouge">reward</code> in a particular <code class="language-plaintext highlighter-rouge">state</code> until the end of the <code class="language-plaintext highlighter-rouge">episode</code> following a particular <code class="language-plaintext highlighter-rouge">policy</code> also considering <code class="language-plaintext highlighter-rouge">discounts</code>.</li>
</ul>

<p>Hang on, the definition of <code class="language-plaintext highlighter-rouge">Q-value</code> and <code class="language-plaintext highlighter-rouge">Value</code> are similar. Are they the same?</p>

<p>Think of <code class="language-plaintext highlighter-rouge">Value</code> as the label, and <code class="language-plaintext highlighter-rouge">Q-value</code> is the predicted outcome. The <code class="language-plaintext highlighter-rouge">policy</code> is supposed to be updated. With this statement in mind, we actually have some sort of gradient here we can optimize!</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Advantage Function</code> :The difference between the <code class="language-plaintext highlighter-rouge">Q-value</code> and the <code class="language-plaintext highlighter-rouge">Value</code>.</li>
</ul>

<p>These are all the important terms, I’ll be writing a separate article on model based and model free. Do keep an eye on it!</p>

<p>That’s it for today! These should be pretty easy to remember right? The following article will closely tie to this article so stay tuned!</p>

<p>References:</p>
<ul>
  <li>[https://towardsdatascience.com/the-complete-reinforcement-learning-dictionary-e16230b7d24e]</li>
  <li>[https://skymind.ai/wiki/deep-reinforcement-learning#define]</li>
</ul>

  </div>

    </div>
  </div>



    <div class="container-md p-3 text-gray text-center"> Copyright &#169 ModelConverge 2020</div>
  </div>
</body>
</html>

