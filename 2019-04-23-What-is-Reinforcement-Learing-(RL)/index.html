







<!--  -->




<!--  -->

<!doctype html>
<html class="height-full">
  <head>
    <meta charset="utf-8">
    <meta name="description" content="PrefaceI am a student studying in Singapore Polytechnic, currently in year 3. I truly enjoy what my course, Diploma in Computer Engineering has to offer. However, I have yet to see a chance to explore some of my ideas I have since I was year one. Over the years of hackathons, projects, and most i..." />
    <title>Bryan Tee Pak Hong</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="/assets/styles.css" rel="stylesheet" type="text/css">
  </head>
  <body class="bg-blue container-no-scroll" >





  <div class="container-lg py-6 p-responsive text-center bg-contrast-blue height-full">

    

<div class="container-md p-3 p-sm-5 " style="text-align: center;">
  <table class="border border-0">
    <tbody class="border border-0">
    <tr class="border border-0">
      <td class="border border-0">
        <div style="text-align: center;">
          <div style="margin: auto; position: relative;">
            <img src="https://avatars2.githubusercontent.com/u/34470507?v=4" class="circle mt-3 mb-3" style="max-width: 150px; margin-left: auto; margin-right: auto;"> 
          </div>
        </div>
      </td>
      <td class="border border-0">
        <h1 class=" mb-2 lh-condensed text-left">Bryan <br/>Tee Pak Hong</h1>
         <p class="mb-3 f4 text-gray text-left">
          Get Up, Dress Up, Show Up, and Never Give Up!
        </p>
      </td>
    </tr>
    </tbody>
  </table>
</div>

<nav class="UnderlineNavi container-md"> 
    <div class="UnderlineNav-body" style="display: block">
      <a href="/" role="tab" title="Home" class="UnderlineNav-item selected">Blog</a>
      <!-- <a href="/digitalFabrication" role="tab" title="Digital Fabrication" class="UnderlineNav-item ">Digital Fabrication</a> -->
      <a href="/myprojects" role="tab" title="My Projects" class="UnderlineNav-item ">My Projects</a>
      <a href="/about" role="tab" title="About" class="UnderlineNav-item ">About</a>
    </div>
  </nav>

    <div class="container-xl f4 text-left border rounded-2 bg-white p-3 p-sm-5 mt-6">
      <p class="f5"><a href="/" class="d-flex flex-items-center"><svg height="16" class="octicon octicon-chevron-left mr-2 v-align-middle" fill="#0366d6" aria-label="Home" viewBox="0 0 16 16" version="1.1" width="16" role="img"><path fill-rule="evenodd" d="M9.78 12.78a.75.75 0 01-1.06 0L4.47 8.53a.75.75 0 010-1.06l4.25-4.25a.75.75 0 011.06 1.06L6.06 8l3.72 3.72a.75.75 0 010 1.06z"></path></svg>Back</a></p>
      <h1 class="f00-light lh-condensed">What is Reinforcement Learning (RL)</h1>
      <p class="text-gray ">Published Apr 23, 2019</p>
      
  
  <div class="article">
    <h1 id="preface">Preface</h1>
<p>I am a student studying in Singapore Polytechnic, currently in year 3. I truly enjoy what my course, Diploma in Computer Engineering has to offer. However, I have yet to see a chance to explore some of my ideas I have since I was year one. Over the years of hackathons, projects, and most importantly guidance from mentors and peers, I feel like I know enough to learn RL at my own pace. This blog is to document what I have learnt over a two-week from my school holiday.</p>

<h2 id="fundementals">FUNdementals</h2>
<p>To discuss RL in specific terms, it is important to understand the following terminology:</p>
<ul>
  <li><code class="highlighter-rouge">agent</code> : this is an algorithm in your machine that you train to achieve your goal</li>
  <li><code class="highlighter-rouge">environment</code> : this is the place your <code class="highlighter-rouge">agent</code> interacts with</li>
  <li><code class="highlighter-rouge">state</code> :  The instantaneous situation the agent finds itself in in relation to other factors.</li>
  <li><code class="highlighter-rouge">action</code> : This is the step that your agent takes upon determining from the multitude of possible steps from a <code class="highlighter-rouge">state</code></li>
  <li><code class="highlighter-rouge">reward</code> : A feedback used to measure the success/failure of the <code class="highlighter-rouge">agent</code>.</li>
  <li><code class="highlighter-rouge">discount</code> : As time goes on, we all die. This is why we include the discount factor, to maximize time to live and do not let the “end game” <code class="highlighter-rouge">action</code>s affect the early game performance.</li>
  <li><code class="highlighter-rouge">episode</code> : The session the agent runs from start to finish.</li>
</ul>

<p>At the core of RL, we want the agent to learn the best actions to achieve a particular outcome through trial and error. There are multiple methods to be discussed but releasing it all in one article just spoils all the fun hehehe. Today we focus more on the technical terms.</p>

<p>Using the definitions above, we can see how they come together. The <code class="highlighter-rouge">agent</code> is what we have designed. The <code class="highlighter-rouge">environment</code> is a function/black box that transforms the <code class="highlighter-rouge">agent</code>’s current <code class="highlighter-rouge">state</code> and <code class="highlighter-rouge">action</code> taken into the next <code class="highlighter-rouge">state</code> and a feedback(<code class="highlighter-rouge">reward</code>), while the <code class="highlighter-rouge">agent</code> <code class="highlighter-rouge">transforms</code> the new <code class="highlighter-rouge">state</code> and <code class="highlighter-rouge">reward</code> into a next <code class="highlighter-rouge">action</code>. The <code class="highlighter-rouge">agent</code>’s job is to approximate the <code class="highlighter-rouge">environment</code>’s function to find the maximum <code class="highlighter-rouge">reward</code> it produces after each <code class="highlighter-rouge">episode</code>. A <code class="highlighter-rouge">discount</code> can be added to allow high performance early in the <code class="highlighter-rouge">episode</code> (and possibly forever!).</p>

<p><img src="/images/RL-flow.png" alt="RL-flow" /></p>

<p>So, using the above phenomena, we can observe more phenomenas and they can be expressed mathematically. Hence, let’s also define a few terms:</p>

<ul>
  <li><code class="highlighter-rouge">policy</code> : A strategy that the <code class="highlighter-rouge">agent</code> uses to determine the next <code class="highlighter-rouge">action</code> based on the current <code class="highlighter-rouge">state</code>. It maps <code class="highlighter-rouge">state</code>s to <code class="highlighter-rouge">action</code>s of highest <code class="highlighter-rouge">reward</code>.</li>
  <li><code class="highlighter-rouge">Q-value</code> or <code class="highlighter-rouge">action-value</code> : <code class="highlighter-rouge">Q</code> is a abbreviation for <code class="highlighter-rouge">Quality</code>. This is the expected long-term return with <code class="highlighter-rouge">discount</code>, taking into consideration of <code class="highlighter-rouge">action</code>. This value maps <code class="highlighter-rouge">state-action pairs</code> to <code class="highlighter-rouge">rewards</code>, having a subtle difference with <code class="highlighter-rouge">policy</code>.</li>
  <li><code class="highlighter-rouge">Value</code> : the overall expected <code class="highlighter-rouge">reward</code> in a particular <code class="highlighter-rouge">state</code> until the end of the <code class="highlighter-rouge">episode</code> following a particular <code class="highlighter-rouge">policy</code> also considering <code class="highlighter-rouge">discounts</code>.</li>
</ul>

<p>Hang on, the definition of <code class="highlighter-rouge">Q-value</code> and <code class="highlighter-rouge">Value</code> are similar. Are they the same?</p>

<p>Think of <code class="highlighter-rouge">Value</code> as the label, and <code class="highlighter-rouge">Q-value</code> is the predicted outcome. The <code class="highlighter-rouge">policy</code> is supposed to be updated. With this statement in mind, we actually have some sort of gradient here we can optimize!</p>

<ul>
  <li><code class="highlighter-rouge">Advantage Function</code> :The difference between the <code class="highlighter-rouge">Q-value</code> and the <code class="highlighter-rouge">Value</code>.</li>
</ul>

<p>These are all the important terms, I’ll be writing a separate article on model based and model free. Do keep an eye on it!</p>

<p>That’s it for today! These should be pretty easy to remember right? The following article will closely tie to this article so stay tuned!</p>

<p>References:</p>
<ul>
  <li>[https://towardsdatascience.com/the-complete-reinforcement-learning-dictionary-e16230b7d24e]</li>
  <li>[https://skymind.ai/wiki/deep-reinforcement-learning#define]</li>
</ul>

  </div>

    </div>
  </div>



    <div class="container-md p-3 text-gray text-center"> Copyright &#169 ModelConverge 2020</div>
  </div>
</body>
</html>

